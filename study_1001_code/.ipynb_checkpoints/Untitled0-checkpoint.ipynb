{
 "metadata": {
  "name": "",
  "signature": "sha256:7c22d38801f1179155fee25ef1925197142bd388ea5549bb25f19ec6b9b3d3d1"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testing random things as they come up:"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import random\n",
      "import glob\n",
      "import string\n",
      "\n",
      "x = np.arange(1,10,1).reshape((3,3))\n",
      "print x\n",
      "y = np.arange(4,13,1).reshape((3,3))\n",
      "print y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[1 2 3]\n",
        " [4 5 6]\n",
        " [7 8 9]]\n",
        "[[ 4  5  6]\n",
        " [ 7  8  9]\n",
        " [10 11 12]]\n"
       ]
      }
     ],
     "prompt_number": 105
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df1\n",
      "\n",
      "df1['new'] = ['bla h', 'b ;azz', 'killme']\n",
      "print df1\n",
      "\n",
      "#misc['product_desc'] = misc['product_desc'].str.replace('\\n', '')\n",
      "\n",
      "df1['new'] = df1['new'].str.replace(\" \", \"\")\n",
      "\n",
      "\n",
      "\n",
      "#df1.apply(lambda x: x[3].replace(\" \", \"\"),1)\n",
      "print df1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   a  b  c     new\n",
        "0  1  2  3   bla h\n",
        "1  4  5  6  b ;azz\n",
        "2  7  8  9  killme\n",
        "   a  b  c     new\n",
        "0  1  2  3    blah\n",
        "1  4  5  6   b;azz\n",
        "2  7  8  9  killme\n"
       ]
      }
     ],
     "prompt_number": 114
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df1 = pd.DataFrame(data = x, columns = ['a','b','c'])\n",
      "\n",
      "df2 = pd.DataFrame(data = y, columns = ['x','y','z'])\n",
      "\n",
      "\n",
      "\n",
      "keys = df2.x.tolist()\n",
      "values = df2.y.tolist()\n",
      "\n",
      "\n",
      "dictt = dict(zip(keys,values))\n",
      "print dictt\n",
      "\n",
      "df2['new'] = np.nan\n",
      "print df2\n",
      "\n",
      "def f(s, dic):\n",
      "    s[3] = dic[s[0]]\n",
      "    return s\n",
      "\n",
      "for row in df2.iterrows():\n",
      "    print row[1][0]\n",
      "    df2.ix[df2['x']==row[1][0], 'new'] = dictt[row[1][0]]\n",
      "\n",
      "\n",
      "#df2.apply(f( dictt),1)\n",
      "#df2['newcolumn'] = df2.apply(lambda x: f(x, dictt), axis=1)\n",
      "\n",
      "print df2\n",
      "\n",
      "# does this shit work at all?\n",
      "\n",
      "# plan\n",
      "# iterate through df1,\n",
      "# for each row in df1,\n",
      "# df2[assignmentcolumn] = value in df1 where comparison column in df2 = comparison in df1s iterated row\n",
      "#for row in edges.iterrows():\n",
      " #   edges['seq1'][ edges['feature1'] == row[1][0] ] = rep_seqs['sequence'][rep_seqs['taxa'] == row[1][0]]\n",
      "\n",
      "\n",
      "    \n",
      "\n",
      "#for row in df2.iterrows():\n",
      "#    df2['new'][df2['x'] == row[1][0]] = df1row[1][1]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{10: 11, 4: 5, 7: 8}\n",
        "    x   y   z  new\n",
        "0   4   5   6  NaN\n",
        "1   7   8   9  NaN\n",
        "2  10  11  12  NaN\n",
        "4.0\n",
        "7.0\n",
        "10.0\n",
        "    x   y   z  new\n",
        "0   4   5   6    5\n",
        "1   7   8   9    8\n",
        "2  10  11  12   11\n"
       ]
      }
     ],
     "prompt_number": 99
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import time\n",
      "import numpy as np\n",
      "import numpy as np\n",
      "import glob\n",
      "\n",
      "def Import_Data(files):\n",
      "    dict_master = {}\n",
      "    #dict = {}\n",
      "    for f in files:\n",
      "        with open(f) as in_file:\n",
      "            mess = in_file.readlines()\n",
      "            #print mess\n",
      "            index = int(mess[1].split('\\t')[1].strip('\\r\\n'))\n",
      "            if not index in dict_master:\n",
      "                dict_master[index] = {}\n",
      "            #print index\n",
      "            data_0 = np.float64(mess[8].split('\\t')[1].strip('\\r\\n'))\n",
      "            data_1 = np.float64(mess[9].split('\\t')[1].strip('\\r\\n'))\n",
      "            i = int(f.split('Int')[0].split('Seq')[1])\n",
      "            dict_master[index][i]=[data_0, data_1]\n",
      "            #dict_master[index] = dict\n",
      "    return dict_master\n",
      "\n",
      "# make dict([('temperature', 0, ('S1_0', 0), ('S1_1', 0), ('S1/R_0', 0), ('S1/R_1', 0)])\n",
      "# /Users/MXW/documents/Mirkin Lab/Data & Protocols/QD Lattice/20130513 Fluorologmeltdata/Melt.5.13.2013/\n",
      "# /Users/MXW/documents/Mirkin Lab/Data & Protocols/QD Lattice/20130513 Fluorologmeltdata/test.txt\n",
      "\n",
      "if  __name__ =='__main__':\n",
      "    directory = raw_input(\"File Path for Data text Files:\"+\"\\t\")\n",
      "    out_directory = raw_input(\"File Path and name without .txt:\"+\"\\t\")\n",
      "    temp_correction = raw_input(\"starting temperature:\")\n",
      "    # samp_number = raw_input(\"number of samples:\")\n",
      "    data_points = raw_input(\"number of temperature points:\")\n",
      "\n",
      "    temp_correction = int(temp_correction)\n",
      "    data_points = int(data_points)\n",
      "    \n",
      "    # print directory, out_directory\n",
      "    files = glob.glob(directory + \"*.txt\")\n",
      "\n",
      "    corrected_files = [a for a in files if '%' in a]\n",
      "    uncorrected_files = [a for a in files if not '%' in a] \n",
      "\n",
      "    uncorrected = Import_Data(uncorrected_files)\n",
      "    corrected = Import_Data(corrected_files)\n",
      "    print corrected\n",
      "    # print len(corrected_files)\n",
      "    data_array = np.ndarray((data_points,8))    \n",
      "    \n",
      "    \n",
      "    for k, __ in uncorrected.iteritems():\n",
      "        with open(out_directory + str(k) + \".txt\", 'w') as out_file:\n",
      "            #print corrected\n",
      "            for j in range(data_points):\n",
      "                temp = temp_correction + int(j)\n",
      "                #print uncorrected[k]\n",
      "                S1_0 = uncorrected[k][j][0]\n",
      "                S1_1 = uncorrected[k][j][1]\n",
      "                S1R_0 = corrected[k][j][0]\n",
      "                S1R_1 = corrected[k][j][1]\n",
      "                S1_av = (S1_0 + S1_1)/2\n",
      "                S1R_av = (S1R_0 + S1R_1)/2\n",
      "                data_array[j]=[j, temp, S1_0, S1_1, S1_av, S1R_0, S1R_1, S1R_av]\n",
      "                line = str(j) +'\\t' + str(temp) +'\\t'+str(S1_0)+'\\t'+str(S1_1)+'\\t'+ str(S1_av) + '\\t' + str(S1R_0)+'\\t'+str(S1R_1)+ '\\t' + str(S1R_av) + '\\t'+ '\\n'\n",
      "                out_file.write(line)\n",
      "    \n",
      "    # print uncorrected_files\n",
      "    # print corrected\n",
      "\n",
      "# Plot data\n",
      "    import matplotlib.pyplot as plt\n",
      "    plt.close('all')\n",
      "    p1 = plt.plot(data_array[:,1], data_array[:,4], 'r--', label='S1 average')\n",
      "    p2 = plt.plot(data_array[:,1], data_array[:,7], 'b*', label='S1R average')\n",
      "    plt.ylabel('Fluorescence')\n",
      "    plt.legend()\n",
      "    plt.xlabel('Temperature (C)')\n",
      "    plt.title('QD Substrate Melt')\n",
      "    plt.show()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "File Path for Data text Files:\t\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "File Path and name without .txt:\t\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "starting temperature:\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "number of temperature points:\n"
       ]
      },
      {
       "ename": "ValueError",
       "evalue": "invalid literal for int() with base 10: ''",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-20-3c99acadaa9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mdata_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"number of temperature points:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mtemp_correction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_correction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mdata_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: ''"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "files = glob.glob('/Users/jimbo/Desktop/25Her2' + \"*.txt\")\n",
      "print files"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[]\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "What do I need to check. Consistency between different versions of data from qiime.\n",
      "I'm going to start with data from load otus and see if it makes sense for synthetic dataset with duplicates. also if it makese sense for data I have so far. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n",
        "1\n"
       ]
      }
     ],
     "prompt_number": 115
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}